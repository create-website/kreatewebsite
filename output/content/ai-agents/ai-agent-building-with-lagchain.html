<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Interactive Guide: Building Production-Ready AI Agents</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <!-- Chosen Palette: Warm Neutral Stone -->
    <!-- Application Structure Plan: A responsive single-page application with a fixed sidebar for primary navigation, representing the six stages of the agent development lifecycle. Clicking a navigation item dynamically displays the corresponding content section in the main view without a page reload. This master-detail structure provides a constant map of the process, allowing users to explore the guide non-linearly while understanding their position in the overall workflow. This design transforms the linear document into a manageable, explorable application, prioritizing user-friendliness and intuitive navigation. -->
    <!-- Visualization & Content Choices: The application uses structured HTML and Tailwind CSS to create visual hierarchy and engagement. Key concepts are highlighted in distinct "callout cards" with icons (Unicode). Code snippets are presented in styled blocks with a "copy-to-clipboard" interaction. The final comparison table is implemented as a responsive HTML table. No charts are needed as the source material is conceptual, but Chart.js is included per instructions. The goal is to make dense, technical information scannable and interactive. -->
    <!-- CONFIRMATION: NO SVG graphics used. NO Mermaid JS used. -->
    <style>
        body {
            font-family: 'Inter', sans-serif;
            background-color: #f5f5f4; /* stone-100 */
        }
        .nav-link {
            transition: all 0.2s ease-in-out;
        }
        .nav-link.active {
            background-color: #e7e5e4; /* stone-200 */
            color: #1c1917; /* stone-900 */
            font-weight: 600;
        }
        .content-section {
            display: none;
        }
        .content-section.active {
            display: block;
        }
        .code-block {
            position: relative;
        }
        .copy-btn {
            position: absolute;
            top: 0.5rem;
            right: 0.5rem;
            background-color: #e7e5e4;
            color: #57534e;
            padding: 0.25rem 0.5rem;
            border-radius: 0.375rem;
            font-size: 0.75rem;
            font-weight: 500;
            cursor: pointer;
            transition: all 0.2s ease-in-out;
        }
        .copy-btn:hover {
            background-color: #d6d3d1;
        }
    </style>
</head>
<body class="text-stone-800">

    <div class="flex min-h-screen">
        <!-- Sidebar Navigation -->
        <aside class="w-64 bg-white border-r border-stone-200 p-4 flex-col hidden md:flex">
            <h1 class="text-xl font-bold text-stone-900 mb-6">AI Agent Guide</h1>
            <nav id="sidebar-nav" class="flex flex-col space-y-2">
                <a href="#" class="nav-link active px-3 py-2 rounded-lg text-stone-600 hover:bg-stone-100" data-target="part1">1. Define Mandate</a>
                <a href="#" class="nav-link px-3 py-2 rounded-lg text-stone-600 hover:bg-stone-100" data-target="part2">2. Architect SOP</a>
                <a href="#" class="nav-link px-3 py-2 rounded-lg text-stone-600 hover:bg-stone-100" data-target="part3">3. Build MVP</a>
                <a href="#" class="nav-link px-3 py-2 rounded-lg text-stone-600 hover:bg-stone-100" data-target="part4">4. Connect to World</a>
                <a href="#" class="nav-link px-3 py-2 rounded-lg text-stone-600 hover:bg-stone-100" data-target="part5">5. Test & Evaluate</a>
                <a href="#" class="nav-link px-3 py-2 rounded-lg text-stone-600 hover:bg-stone-100" data-target="part6">6. Deploy & Refine</a>
            </nav>
        </aside>

        <!-- Main Content -->
        <main class="flex-1 p-4 sm:p-6 lg:p-8">
            <!-- Mobile Navigation -->
            <div class="md:hidden mb-4">
                <select id="mobile-nav" class="w-full p-2 border border-stone-300 rounded-lg bg-white">
                    <option value="part1">1. Define Mandate</option>
                    <option value="part2">2. Architect SOP</option>
                    <option value="part3">3. Build MVP</option>
                    <option value="part4">4. Connect to World</option>
                    <option value="part5">5. Test & Evaluate</option>
                    <option value="part6">6. Deploy & Refine</option>
                </select>
            </div>

            <!-- Part 1: Define Mandate -->
            <section id="part1" class="content-section active">
                <h2 class="text-3xl font-bold text-stone-900 mb-2">Part 1: Defining the Agent's Mandate</h2>
                <p class="text-lg text-stone-600 mb-6">This initial stage is the most critical. It's where we move from a vague idea to a concrete, testable task. Success here dictates the success of the entire project. This section provides a strategic framework for properly scoping your agent's job.</p>
                
                <div class="space-y-6">
                    <div class="bg-white p-6 rounded-xl border border-stone-200">
                        <h3 class="text-xl font-semibold text-stone-800 mb-3">üí° 1.1 The "Smart Intern" Test: Scoping a Realistic Task</h3>
                        <p class="text-stone-700 mb-4">The first principle is realism. If you couldn't teach a smart, capable intern to do the task, it's too ambitious for an initial AI agent. This test forces a pragmatic assessment of complexity and ensures you start with an achievable goal.</p>
                        <div class="bg-stone-50 p-4 rounded-lg border border-stone-200">
                            <h4 class="font-semibold text-stone-700 mb-2">Example: Deconstructing "Email Agent"</h4>
                            <ul class="list-disc list-inside text-stone-600 space-y-1">
                                <li><span class="font-semibold">Too Broad:</span> "Manage my email."</li>
                                <li><span class="font-semibold text-green-700">Well-Scoped:</span> "Prioritize urgent emails," "Schedule meetings from requests," "Filter spam," and "Answer product questions using documentation."</li>
                            </ul>
                        </div>
                    </div>

                    <div class="bg-white p-6 rounded-xl border border-stone-200">
                        <h3 class="text-xl font-semibold text-stone-800 mb-3">üéØ 1.2 Establishing a Performance Baseline with Concrete Examples</h3>
                        <p class="text-stone-700 mb-4">Create 5-10 concrete examples of the agent's core functions. This validates the scope and creates the first version of your benchmark dataset, giving you a clear measure of success from day one.</p>
                         <div class="bg-stone-50 p-4 rounded-lg border border-stone-200">
                            <h4 class="font-semibold text-stone-700 mb-2">Example: Meeting Scheduling</h4>
                            <p class="text-stone-600"><span class="font-semibold">Input:</span> Email saying "Are you free next Tuesday afternoon?"</p>
                            <p class="text-stone-600"><span class="font-semibold">Expected Output:</span> Action: `Check calendar`, Action: `Draft reply with available slots`. </p>
                        </div>
                    </div>

                    <div class="bg-amber-50 p-6 rounded-xl border border-amber-200">
                        <h3 class="text-xl font-semibold text-amber-800 mb-3">‚ö†Ô∏è 1.3 Red Flags and Anti-Patterns in Task Definition</h3>
                        <ul class="list-disc list-inside text-amber-700 space-y-2">
                            <li><strong>Overly Broad Scope:</strong> "Be a marketing assistant" will fail. "Draft five tweets from a blog post" is a good start.</li>
                            <li><strong>Inappropriate Use of Agents:</strong> If the logic is simple and deterministic, use traditional software. Agents are for complex reasoning and natural language tasks.</li>
                            <li><strong>Expecting Magic:</strong> An agent can't use tools or data that don't exist. Its world is defined by the tools you give it. A poorly defined task leads to "agentic technical debt."</li>
                        </ul>
                    </div>
                </div>
            </section>

            <!-- Part 2: Architect SOP -->
            <section id="part2" class="content-section">
                <h2 class="text-3xl font-bold text-stone-900 mb-2">Part 2: Architecting the Standard Operating Procedure (SOP)</h2>
                <p class="text-lg text-stone-600 mb-6">After defining the task, create a detailed, human-centric workflow. This SOP becomes the direct blueprint for the agent's logic, prompt, and tools. Documenting the human process first makes the task concrete and exposes complexities before you write any code.</p>

                <div class="bg-white p-6 rounded-xl border border-stone-200">
                    <h3 class="text-xl font-semibold text-stone-800 mb-3">‚úçÔ∏è 2.1 From Task to Workflow: Documenting the Human Process</h3>
                    <p class="text-stone-700 mb-4">An SOP breaks the task into a sequence of logical steps. Below is a simplified SOP for a social media sentiment analysis agent.</p>
                    <div class="space-y-4">
                        <div class="p-4 rounded-lg bg-stone-50 border border-stone-200">
                            <p class="font-semibold"><strong>Step 1: Monitor for Brand Mentions.</strong> Track keywords and set up alerts for volume spikes.</p>
                        </div>
                        <div class="p-4 rounded-lg bg-stone-50 border border-stone-200">
                            <p class="font-semibold"><strong>Step 2: Analyze Mention Content.</strong> Classify sentiment (Positive, Negative, Neutral) and theme (Feedback, Support, Praise).</p>
                        </div>
                        <div class="p-4 rounded-lg bg-stone-50 border border-stone-200">
                            <p class="font-semibold"><strong>Step 3: Triage and Prioritize.</strong> Flag mentions based on a sentiment/theme matrix (e.g., Negative + Support = High Priority).</p>
                        </div>
                        <div class="p-4 rounded-lg bg-stone-50 border border-stone-200">
                            <p class="font-semibold"><strong>Step 4: Formulate and Execute Response.</strong> Draft responses, require human review for high-priority cases, and post/like others.</p>
                        </div>
                    </div>
                </div>

                <div class="bg-white p-6 rounded-xl border border-stone-200 mt-6">
                    <h3 class="text-xl font-semibold text-stone-800 mb-3">üß© 2.2 Deconstructing the SOP into Agent Components</h3>
                    <p class="text-stone-700 mb-4">Translate the SOP directly into technical components for your LangChain agent.</p>
                     <ul class="list-disc list-inside text-stone-700 space-y-2">
                        <li><strong>Tool Identification:</strong> `Keyword Tracking` -> `Web Search Tool`. `Sentiment Analysis` -> `LLM Reasoning Call`. `Post Response` -> `Social Media API Tool`.</li>
                        <li><strong>Memory Requirements:</strong> The need to avoid duplicate replies implies a need for `Memory` to track processed mentions.</li>
                        <li><strong>Core Reasoning Steps:</strong> The triage logic (Step 3) is the intellectual heart of the agent and will become the focus of the MVP prompt. The SOP provides a pre-validated thought process for ReAct-style prompting.</li>
                    </ul>
                </div>
            </section>

            <!-- Part 3: Build MVP -->
            <section id="part3" class="content-section">
                <h2 class="text-3xl font-bold text-stone-900 mb-2">Part 3: Building the Agent's Core: The MVP Prompt</h2>
                <p class="text-lg text-stone-600 mb-6">This is where we transition from planning to code. The goal is to build a focused Minimum Viable Product (MVP) to validate the agent's single most critical reasoning step before adding complex infrastructure.</p>

                <div class="bg-white p-6 rounded-xl border border-stone-200 mb-6">
                    <h3 class="text-xl font-semibold text-stone-800 mb-3">‚öôÔ∏è 3.1 Core LangChain Agent Components</h3>
                    <p class="text-stone-700 mb-4">An agent is built from three fundamental blocks:</p>
                    <ul class="space-y-4">
                        <li><strong class="text-stone-900">The LLM:</strong> The agent's "brain." Choose a model and set temperature to 0.0 for more predictable behavior.</li>
                        <li class="code-block">
                            <button class="copy-btn" data-clipboard-target="#code1">Copy</button>
                            <pre id="code1" class="bg-stone-100 text-sm p-4 rounded-lg overflow-x-auto"><code class="language-python">from langchain_openai import ChatOpenAI

llm = ChatOpenAI(
    model_name="gpt-4o-mini",
    temperature=0.0,
)</code></pre>
                        </li>
                        <li><strong class="text-stone-900">Tools:</strong> The agent's "hands and eyes." A tool is a Python function with a clear docstring, which the LLM uses to understand its purpose.</li>
                        <li class="code-block">
                            <button class="copy-btn" data-clipboard-target="#code2">Copy</button>
                            <pre id="code2" class="bg-stone-100 text-sm p-4 rounded-lg overflow-x-auto"><code class="language-python">from langchain_core.tools import tool

@tool
def get_sentiment_and_theme(text: str) -> dict:
    """
    Analyzes input text to determine its sentiment and theme.
    Use this tool as the first step to understand a social media mention.
    """
    # ... implementation ...
    return {"sentiment": "Positive", "theme": "General Praise"}</code></pre>
                        </li>
                        <li><strong class="text-stone-900">AgentExecutor:</strong> The runtime that orchestrates the "Thought, Action, Observation" loop, executing tools and feeding results back to the LLM.</li>
                    </ul>
                </div>
                
                <div class="bg-white p-6 rounded-xl border border-stone-200">
                    <h3 class="text-xl font-semibold text-stone-800 mb-3">üß† 3.3 Building the MVP: Isolate, Prompt, and Validate</h3>
                    <p class="text-stone-700 mb-4">The MVP methodology ensures the agent's core logic is sound before adding complexity.</p>
                    <ol class="list-decimal list-inside text-stone-700 space-y-2">
                        <li><strong>Isolate the Core Task:</strong> Focus on the most critical reasoning step (e.g., the triage decision).</li>
                        <li><strong>Manually Feed Inputs:</strong> Use your benchmark examples and mocked tools to test the agent's reasoning in isolation.</li>
                        <li><strong>Validate with Tracing:</strong> Use a tool like LangSmith to trace the agent's execution. Check if it called the right tools with the right arguments. If not, refine the prompt. This iterative cycle is key: <strong>Prompt -> Test -> Trace -> Refine</strong>.</li>
                    </ol>
                </div>
            </section>
            
            <!-- Part 4: Connect to World -->
            <section id="part4" class="content-section">
                <h2 class="text-3xl font-bold text-stone-900 mb-2">Part 4: Connecting the Agent to the Real World</h2>
                <p class="text-lg text-stone-600 mb-6">Once the core reasoning is validated, it's time to connect the agent to live data sources and APIs. This section also covers giving the agent memory to maintain context in conversations.</p>

                <div class="bg-white p-6 rounded-xl border border-stone-200 mb-6">
                    <h3 class="text-xl font-semibold text-stone-800 mb-3">üîå 4.1 Orchestrating Data with Tools and APIs</h3>
                    <p class="text-stone-700 mb-4">Implement real tools that handle authentication, make API calls, and parse results. LangChain Toolkits simplify this for services like Gmail, Google Calendar, SQL databases, and web search.</p>
                    <div class="code-block">
                        <button class="copy-btn" data-clipboard-target="#code3">Copy</button>
                        <pre id="code3" class="bg-stone-100 text-sm p-4 rounded-lg overflow-x-auto"><code class="language-python">from langchain_community.agent_toolkits import create_sql_agent
from langchain_community.utilities import SQLDatabase

db = SQLDatabase.from_uri("sqlite:///./Chinook.db")
# llm is a pre-initialized ChatOpenAI model
sql_agent_executor = create_sql_agent(llm, db=db, agent_type="openai-tools")

sql_agent_executor.invoke({"input": "Which artist has the most albums?"})</code></pre>
                    </div>
                    <div class="mt-4 bg-sky-50 p-4 rounded-lg border border-sky-200">
                        <p class="font-semibold text-sky-800">Key Insight: Tool Docstrings are Micro-Prompts</p>
                        <p class="text-sky-700">The LLM's entire understanding of a tool comes from its name and docstring. A vague docstring leads to incorrect tool use. Writing a high-quality, descriptive docstring is an act of programming the agent's decision-making process.</p>
                    </div>
                </div>

                <div class="bg-white p-6 rounded-xl border border-stone-200">
                    <h3 class="text-xl font-semibold text-stone-800 mb-3">üíæ 4.2 Managing State and Context with Memory</h3>
                    <p class="text-stone-700 mb-4">Memory allows an agent to retain information from previous turns in a conversation. This is essential for coherent, multi-turn interactions.</p>
                    <ul class="list-disc list-inside text-stone-700 space-y-2">
                        <li><strong>ConversationBufferMemory:</strong> Stores the entire chat history. Simple but can exceed context windows.</li>
                        <li><strong>SummaryMemory:</strong> Maintains a running summary of the conversation. More token-efficient for long chats.</li>
                        <li><strong>Vector DB-backed Memory:</strong> For long-term, cross-session memory, store interactions in a vector database for similarity search.</li>
                    </ul>
                </div>
            </section>

            <!-- Part 5: Test & Evaluate -->
            <section id="part5" class="content-section">
                <h2 class="text-3xl font-bold text-stone-900 mb-2">Part 5: A Framework for Rigorous Testing and Evaluation</h2>
                <p class="text-lg text-stone-600 mb-6">The non-deterministic nature of LLMs requires a multi-faceted evaluation framework. This is a necessity for building reliable agents, moving from manual inspection to programmatic measurement of performance.</p>
                
                <div class="grid md:grid-cols-2 gap-6">
                    <div class="bg-white p-6 rounded-xl border border-stone-200">
                        <h3 class="text-xl font-semibold text-stone-800 mb-3">üî¨ 5.1 The Observability Stack</h3>
                        <p class="text-stone-700">Before you can measure performance, you must observe it. Tools like <strong>LangSmith</strong> and <strong>Langfuse</strong> are essential for tracing an agent's complex, multi-step execution. Tracing visualizes the entire "Thought, Action, Observation" loop, making it indispensable for debugging.</p>
                    </div>
                    <div class="bg-white p-6 rounded-xl border border-stone-200">
                        <h3 class="text-xl font-semibold text-stone-800 mb-3">üìä 5.2 Defining and Measuring Performance</h3>
                        <p class="text-stone-700">Move beyond subjective impressions to objective KPIs:</p>
                        <ul class="list-disc list-inside text-stone-600 mt-2">
                            <li>Response Quality</li>
                            <li>Tool Usage Efficiency</li>
                            <li>Logical Consistency</li>
                            <li>Latency & Cost</li>
                        </ul>
                    </div>
                </div>

                <div class="bg-white p-6 rounded-xl border border-stone-200 mt-6">
                    <h3 class="text-xl font-semibold text-stone-800 mb-3">üìà 5.3 Advanced Evaluation Methodologies</h3>
                    <p class="text-stone-700 mb-4">Employ rigorous patterns to assess your agent:</p>
                    <ul class="space-y-3">
                        <li><strong>Final Response Evaluation:</strong> Use an "LLM-as-judge" to score the agent's final answer against a reference.</li>
                        <li><strong>Trajectory Evaluation:</strong> Evaluate the agent's *process*, not just its answer. Did it follow the correct sequence of tool calls?</li>
                        <li><strong>Single-Step Evaluation:</strong> Isolate and test a specific, critical decision point, like the agent's first tool choice.</li>
                    </ul>
                    <div class="mt-4 bg-green-50 p-4 rounded-lg border border-green-200">
                        <p class="font-semibold text-green-800">The Feedback Loop is Key</p>
                        <p class="text-green-700">Evaluation is the engine of a continuous development cycle. Failures are not bugs; they are invaluable data points that provide direct, actionable feedback. This creates a powerful loop: <strong>Build -> Test -> Analyze Failures -> Refine -> Re-test</strong>.</p>
                    </div>
                </div>
            </section>

            <!-- Part 6: Deploy & Refine -->
            <section id="part6" class="content-section">
                <h2 class="text-3xl font-bold text-stone-900 mb-2">Part 6: From Launch to Lifecycle: Deployment and Refinement</h2>
                <p class="text-lg text-stone-600 mb-6">Launch is not the end; it's the beginning of the agent's operational lifecycle. This section covers deploying, monitoring, and continuously refining your agent to ensure long-term value.</p>

                <div class="bg-white p-6 rounded-xl border border-stone-200 mb-6">
                    <h3 class="text-xl font-semibold text-stone-800 mb-3">üöÄ 6.1 Production Deployment Architectures</h3>
                    <p class="text-stone-700 mb-4">Wrap your agent's logic in a scalable service architecture.</p>
                    <ul class="list-disc list-inside text-stone-700 space-y-2">
                        <li><strong>API Layer:</strong> Use <strong>FastAPI</strong> and <strong>LangServe</strong> to expose the agent as a REST API, complete with streaming and auto-generated documentation.</li>
                        <li><strong>Containerization:</strong> Package the application with <strong>Docker</strong> for portability and consistency across environments.</li>
                        <li><strong>Orchestration:</strong> Deploy on <strong>Kubernetes</strong> for high availability and automated scaling.</li>
                    </ul>
                </div>

                <div class="bg-white p-6 rounded-xl border border-stone-200 mb-6">
                    <h3 class="text-xl font-semibold text-stone-800 mb-3">üîÑ 6.3 Closing the Loop: Continuous Refinement</h3>
                    <p class="text-stone-700 mb-4">An agent's performance is not static. Build robust feedback loops to drive improvement.</p>
                     <ul class="list-disc list-inside text-stone-700 space-y-2">
                        <li><strong>Human-in-the-Loop (HITL):</strong> For high-stakes tasks, use <strong>LangGraph</strong> to pause execution and await human approval before proceeding.</li>
                        <li><strong>User Feedback:</strong> Collect user feedback (e.g., thumbs up/down) to create a "data flywheel." Negative feedback becomes a valuable data point for your regression test suite and for fine-tuning the agent's prompt or model.</li>
                    </ul>
                </div>

                <div class="bg-white p-6 rounded-xl border border-stone-200">
                    <h3 class="text-xl font-semibold text-stone-800 mb-3">ü§ñ 6.4 Advanced Architectures: Multi-Agent Systems</h3>
                    <p class="text-stone-700 mb-4">As complexity grows, a single agent can become a bottleneck. Use <strong>LangGraph</strong> to create more sophisticated architectures.</p>
                    <div class="overflow-x-auto">
                        <table class="w-full text-left border-collapse">
                            <thead class="bg-stone-50">
                                <tr>
                                    <th class="p-3 font-semibold text-stone-700 border-b border-stone-200">Architecture</th>
                                    <th class="p-3 font-semibold text-stone-700 border-b border-stone-200">Description</th>
                                    <th class="p-3 font-semibold text-stone-700 border-b border-stone-200">Use Case</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr class="hover:bg-stone-50">
                                    <td class="p-3 border-b border-stone-200 font-medium">Single Agent (ReAct)</td>
                                    <td class="p-3 border-b border-stone-200">A single LLM selects from a suite of tools in a loop.</td>
                                    <td class="p-3 border-b border-stone-200">Simple, focused tasks like Q&A with search.</td>
                                </tr>
                                <tr class="hover:bg-stone-50">
                                    <td class="p-3 border-b border-stone-200 font-medium">Multi-Agent Supervisor</td>
                                    <td class="p-3 border-b border-stone-200">A central supervisor agent routes sub-tasks to specialized worker agents.</td>
                                    <td class="p-3 border-b border-stone-200">Complex tasks like a research project involving search, analysis, and writing.</td>
                                </tr>
                                <tr class="hover:bg-stone-50">
                                    <td class="p-3 border-b border-stone-200 font-medium">Hierarchical Agent Teams</td>
                                    <td class="p-3 border-b border-stone-200">An extension where workers can also be supervisors, creating teams of teams.</td>
                                    <td class="p-3 border-b border-stone-200">Highly complex workflows mirroring organizational structures.</td>
                                </tr>
                            </tbody>
                        </table>
                    </div>
                </div>
            </section>
        </main>
    </div>

    <script>
        document.addEventListener('DOMContentLoaded', function () {
            const sidebarNav = document.getElementById('sidebar-nav');
            const mobileNav = document.getElementById('mobile-nav');
            const contentSections = document.querySelectorAll('.content-section');
            const navLinks = document.querySelectorAll('#sidebar-nav .nav-link');

            function showSection(targetId) {
                contentSections.forEach(section => {
                    section.classList.remove('active');
                });
                navLinks.forEach(link => {
                    link.classList.remove('active');
                });

                const targetSection = document.getElementById(targetId);
                if (targetSection) {
                    targetSection.classList.add('active');
                }
                
                const activeLink = document.querySelector(`.nav-link[data-target="${targetId}"]`);
                if (activeLink) {
                    activeLink.classList.add('active');
                }

                if (mobileNav.value !== targetId) {
                    mobileNav.value = targetId;
                }
            }

            if (sidebarNav) {
                sidebarNav.addEventListener('click', function (e) {
                    e.preventDefault();
                    if (e.target.matches('.nav-link')) {
                        const targetId = e.target.getAttribute('data-target');
                        showSection(targetId);
                    }
                });
            }

            if (mobileNav) {
                mobileNav.addEventListener('change', function (e) {
                    showSection(e.target.value);
                });
            }

            const copyButtons = document.querySelectorAll('.copy-btn');
            copyButtons.forEach(button => {
                button.addEventListener('click', function () {
                    const targetId = this.getAttribute('data-clipboard-target');
                    const targetElement = document.querySelector(targetId);
                    if (targetElement) {
                        const textToCopy = targetElement.innerText;
                        navigator.clipboard.writeText(textToCopy).then(() => {
                            this.textContent = 'Copied!';
                            setTimeout(() => {
                                this.textContent = 'Copy';
                            }, 2000);
                        }).catch(err => {
                            console.error('Failed to copy text: ', err);
                        });
                    }
                });
            });
        });
    </script>
</body>
</html>
